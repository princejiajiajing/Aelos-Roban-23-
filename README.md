## Aelos-Roban选拔任务记录
用于记录aelos＆roban选拔任务解决过程

＃任务概述
本项目旨在通过综合使用linux，python，ros，opencv等技术，完成图像处理、目标检测与发布任务。项目分为三个部分：基本任务（图像处理与发布） ）（slam 任务（赛道定位算法）（。以下是项目的详细说明和实现结果。）。以下是项目的详细说明和实现结果。）。以下是项目的详细说明和实现结果。）。以下是项目的详细说明和实现结果。
1.基本任务：图像处理与发布
任务目标
使用python和opencv实现图像处理，框选红色物体并输出其坐标。
编写img_pub.py和img_sub.py两个文件，分别用于图像发布和订阅处理。，分别用于图像发布和订阅处理。，分别用于图像发布和订阅处理。
利用rqt_image工具查看处理后的图像。
实现过程
1.1图像处理
使用opencv库函数，通过颜色阈值分割提取红色物体。，通过颜色阈值分割提取红色物体。，通过颜色阈值分割提取红色物体。
对提取的物体进行框选，并计算其坐标。，并计算其坐标。，并计算其坐标。
输出处理后的图像和物体坐标。
1.2 ROS节点实现
img_pub.py：通过cv_bridge获取摄像头图像
img_sub.py：订阅图像话题，进行图像处理后发布处理后的图像。，进行图像处理后发布处理后的图像。，进行图像处理后发布处理后的图像。
代码结构
img_pub.py：负责图像发布。
img_sub.py：负责图像处理和结果发布。
需求.txt：列出项目依赖的python包。
运行结果
成功框选红色物体，并输出其坐标。，并输出其坐标。，并输出其坐标。
利用rqt_image工具查看处理后的图像，效果良好。，效果良好。，效果良好。
2.进阶任务：Yolo目标识别
任务目标
跑通Yolo框架，完成目标识别。，完成目标识别。，完成目标识别。
将识别到的物体坐标通过ros话题发布。
实现过程
使用Yolov5框架进行目标检测。
在ros中集成Yolo，将检测结果发布到指定话题。
测试视频流中的目标识别功能。
代码结构
yolo_node.py：yolo目标检测节点，发布检测结果。
需求.txt：YOLO相关依赖。
运行结果
成功识别视频中的物体，并输出其像素坐标。，并输出其像素坐标。，并输出其像素坐标。
通过ros话题发布检测结果，验证功能正常。，验证功能正常。，验证功能正常。
3。Slam任务：赛道定位算法
任务目标
学习SLAM相关知识，掌握ORB-SLAM2框架。
完成赛道定位算法的实现。
实现过程
学习高翔《视觉SLAM十四讲》课程，理解SLAM基本原理。
搭建ORB-SLAM2环境，运行仿真测试。
代码结构
ORB_SLAM2：SLAM框架代码。
slam_node.py：ROS节点，用于SLAM功能。
运行结果
成功运行ORB-SLAM2，实现赛道定位。
仿真测试显示定位效果良好，满足任务要求。
4. 学习路线与资源
4.1 Python
书籍：《Python编程 从入门到实践》
视频：B站《超基础Python教程》
教程：菜鸟教程《Python 3 教程》
文档：Python 3.9.7官方文档
4.2 Linux
教程：Linux入门教程
4.3 ROS
教程：古月居《ROS入门21讲》
4.4 OpenCV
教程：B站《OpenCV从入门到实战》
安装：参考CSDN博客《Anaconda安装OpenCV》
5. 补充说明
本项目的主要目的是熟悉Linux系统操作，并跑通全流程。
每一步操作均有详细教程支持，确保任务顺利完成。
如有疑问，可参考相关教程或使用GPT等工具辅助学习。
6. 项目截图与演示
图像处理结果：./images/processed_image.png
YOLO检测结果：./images/yolo_result.png
SLAM仿真效果：./images/slam_simulation.png
7. 项目依赖与环境
操作系统：Ubuntu 20.04
Python版本：Python 3.8
ROS版本：ROS Noetic
OpenCV版本：OpenCV 4.x
YOLO版本：YOLOv5
8. 项目成员与分工
成员1：负责图像处理与ROS节点开发。
成员2：负责YOLO目标识别集成。
成员3：负责SLAM任务实现。
9.项目总结
本项目通过综合使用linux，python，ros，opencv等技术，slam任务。项目过程中，团队成员分工明确，学习路线清晰，最终实现了预期目标。通过实践，我们不仅掌握了相关技术，还积累了项目开发经验。，还积累了项目开发经验。
10.项目代码与资源
代码仓库：github链接
相关教程：教程链接
感谢您的阅读！
